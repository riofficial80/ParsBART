{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMfvYqpWq/Tb9CbK3O7NYre"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["This script is used to train a tokenizer on PN-summary dataset.\n","It trains a Byte-Pair Encoding (BPE) tokenizer using the tokenizers library by HuggingFace.\n","The tokenizer is stored using a format that is compatible with the transformers library."],"metadata":{"id":"4icqDvFASaAt"}},{"cell_type":"code","source":["# Load the Drive helper and mount\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cGDEIeV0VQ-9","executionInfo":{"status":"ok","timestamp":1727958948256,"user_tz":-210,"elapsed":22280,"user":{"displayName":"Ehsan Hosseini","userId":"17288770406484982938"}},"outputId":"8105d421-2005-4276-b0fd-59df00cbb7cb"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install torch transformers datasets tokenizers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xztZZ-K6S4Ey","executionInfo":{"status":"ok","timestamp":1727958958131,"user_tz":-210,"elapsed":9880,"user":{"displayName":"Ehsan Hosseini","userId":"17288770406484982938"}},"outputId":"0a2b1240-2ae2-496a-ab43-e0a5a15c95c5"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n","Collecting datasets\n","  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.19.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.8)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.13.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Downloading datasets-3.0.1-py3-none-any.whl (471 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n","Successfully installed datasets-3.0.1 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"pwNux4qhSUem","executionInfo":{"status":"ok","timestamp":1727958965999,"user_tz":-210,"elapsed":7872,"user":{"displayName":"Ehsan Hosseini","userId":"17288770406484982938"}}},"outputs":[],"source":["import os\n","\n","from transformers import AutoTokenizer, BartTokenizer\n","from tokenizers import ByteLevelBPETokenizer\n","from datasets import load_dataset"]},{"cell_type":"code","source":["# Initialize a tokenizer\n","tokenizer = ByteLevelBPETokenizer()"],"metadata":{"id":"eYzQpoAVSyhu","executionInfo":{"status":"ok","timestamp":1727958966000,"user_tz":-210,"elapsed":4,"user":{"displayName":"Ehsan Hosseini","userId":"17288770406484982938"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Load the dataset to train the tokenizer on\n","dataset = load_dataset(\"HooshvareLab/pn_summary\", split=\"train\", streaming=True)"],"metadata":{"id":"2T7XdJ0CTcQJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uu_fqbn9Tqaj","executionInfo":{"status":"ok","timestamp":1723729912185,"user_tz":-210,"elapsed":391,"user":{"displayName":"Ehsan Hosseini","userId":"17288770406484982938"}},"outputId":"cd887839-17c1-4904-b1e0-c2c6800ac406"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["IterableDataset({\n","    features: ['id', 'title', 'article', 'summary', 'category', 'categories', 'network', 'link'],\n","    n_shards: 1\n","})"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# define iterator function to yield the text from the dataset\n","def iterator():\n","    for example in dataset:\n","        yield example[\"article\"]"],"metadata":{"id":"3oee2_q8Tx3p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the tokenizer using the dataset and the parameters provided\n","tokenizer.train_from_iterator(\n","    iterator(),\n","    vocab_size=52000,\n","    min_frequency=10,\n","    special_tokens=[\n","        \"<s>\",\n","        \"<pad>\",\n","        \"</s>\",\n","        \"<unk>\",\n","        \"<mask>\",\n","    ],\n","    show_progress=True,\n",")"],"metadata":{"id":"LQWVotNsT6SC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cls_token_id = tokenizer.token_to_id(\"<s>\")\n","sep_token_id = tokenizer.token_to_id(\"</s>\")\n","print(cls_token_id, sep_token_id)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RjbDySPMUGiK","executionInfo":{"status":"ok","timestamp":1723730242844,"user_tz":-210,"elapsed":440,"user":{"displayName":"Ehsan Hosseini","userId":"17288770406484982938"}},"outputId":"00982329-fa96-4290-d9bb-ff1fc91c05eb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0 2\n"]}]},{"cell_type":"code","source":["tokenizer_bart_pe = \"/content/drive/MyDrive/Colab Notebooks/ParsBART\"\n","if not os.path.exists(tokenizer_bart_pe):\n","    os.mkdir(tokenizer_bart_pe)\n","tokenizer.model.save(tokenizer_bart_pe)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KVa-GiaMVCkS","executionInfo":{"status":"ok","timestamp":1723730512530,"user_tz":-210,"elapsed":613,"user":{"displayName":"Ehsan Hosseini","userId":"17288770406484982938"}},"outputId":"54b65286-5932-45ae-d415-5f02890a3083"},"execution_count":null,{"cell_type":"code","source":["# Initialize a tokenizer : this is the one that will be used for the training\n","# this trick is needed to comply with the HuggingFace API\n","tokenizer = BartTokenizer(\n","    vocab_file=tokenizer_bart_pe + \"/vocab.json\", merges_file=tokenizer_bart_pe + \"/merges.txt\"\n",")\n","tokenizer.save_pretrained(tokenizer_bart_pe)"],"metadata":{"id":"fAkk_A1yVnZI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(tokenizer_bart_pe)\n","# clean folder that contains the old tokenizer\n","# os.system(\"rm -rf tokenizer\")\n","\n","# Example of encoding a text\n","str_test = \"عجب دنیای عجیبی شده است\"\n","encoded_input = tokenizer(str_test, return_tensors=\"pt\")\n","print(encoded_input)\n","decoded = tokenizer.decode(encoded_input[\"input_ids\"][0], skip_special_tokens=True)\n","print(decoded)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q925WVELWuDu","executionInfo":{"status":"ok","timestamp":1723741243626,"user_tz":-210,"elapsed":483,"user":{"displayName":"Ehsan Hosseini","userId":"17288770406484982938"}},"outputId":"a8e8fa57-8cad-4795-be7e-d468dedb6149"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': [0, 295, 7116, 5013, 11791, 386, 324, 2, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]}\n","عجب دنیای عجیبی شده است\n"]}]},{"cell_type":"code","source":["# corrected_vocab = open(tokenizer_bart_pe+\"/vocab.txt\", \"w\", encoding=\"utf-8\")\n","# with open(tokenizer_bart_pe+\"/vocab.json\", \"r\", encoding=\"utf-8\") as vocab:\n","#   for line in vocab:\n","#     print(line)\n","#     corrected_vocab.write(line)\n","\n","# corrected_vocab.close()"],"metadata":{"id":"nzPK1ijyYAc9"},"execution_count":null,"outputs":[]}]}
